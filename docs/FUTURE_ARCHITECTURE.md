# 未来架构设想：前后端分离 + 云端部署

> 创建时间：2026-02-05
> 状态：待实现

## 目标架构

```
用户本地 (Tauri 桌面应用)          服务器 (Docker)
┌─────────────────────────┐       ┌─────────────────────────┐
│  Tauri App              │       │  FastAPI Backend        │
│  ├─ React 前端          │◄─HTTP─►│  ├─ 音频处理 API        │
│  ├─ 本地文件管理         │       │  ├─ 无状态设计          │
│  └─ 配置管理            │       │  └─ AI 模型             │
├─────────────────────────┤       │      ├─ pyannote        │
│  本地存储               │       │      ├─ whisper         │
│  ├─ outputs/            │       │      └─ llm             │
│  ├─ 用户音频文件         │       └─────────────────────────┘
│  └─ 应用配置            │
└─────────────────────────┘
```

## 核心理念

1. **后端无状态** - Docker 容器纯净，可随时重启/扩容/更新
2. **数据主权** - 用户文件保留在本地，隐私保护更好
3. **多用户共享** - 一个后端实例可服务多个用户
4. **成本分离** - 用户不需要支付服务器存储费用
5. **灵活部署** - 支持本地后端和云端后端切换

## 工作流程

1. 用户在 Tauri 应用中选择音频文件
2. 前端将音频上传到后端 API
3. 后端处理（说话人分离、转写、总结等）
4. 后端返回 JSON 结果（不保存文件）
5. 前端将结果保存到本地

## 需要的改动

### 后端改动

1. **新增上传接口**
   - `POST /api/process/upload` - 接收音频文件
   - 处理完成后返回 JSON 结果
   - 不在服务器保存任何文件

2. **无状态设计**
   - 移除 outputs 目录依赖
   - 所有中间文件使用临时目录，处理完即删除
   - Job 状态可选用 Redis 存储（支持多实例）

3. **Docker 优化**
   - 模型文件通过 volume 挂载
   - 支持 GPU（nvidia-docker）
   - 健康检查接口

### 前端改动

1. **文件管理**
   - 本地 outputs 目录管理
   - 上传进度显示
   - 下载/保存结果

2. **配置管理**
   - 后端地址配置（支持本地/云端切换）
   - API Key 管理（如果需要认证）

3. **离线支持**
   - 检测后端可用性
   - 本地后端 fallback

### API 设计

```
POST /api/process
  - 上传音频文件
  - 返回 job_id

GET /api/jobs/{job_id}
  - 查询处理状态
  - 处理完成时返回完整结果 JSON

# 结果直接在响应中返回，不需要文件下载接口
```

## 参考产品

- Notion AI - 编辑在本地，AI 处理在云端
- GitHub Copilot - 代码在本地，模型在云端
- Adobe Creative Cloud - 重度处理可在云端，文件在本地

## 商业化考虑

1. **定价模式**
   - 按处理时长计费
   - 订阅制（月/年）
   - 免费额度 + 付费升级

2. **认证方案**
   - API Key
   - OAuth（Google/GitHub 登录）

3. **多租户**
   - 用户隔离
   - 使用配额管理

---

*此文档记录架构设想，待当前功能稳定后实施*
