"""
å…¨é¢åˆ†ææ‰€æœ‰ outputsï¼ŒæŒ‡å‡ºé—®é¢˜
"""
import sys
sys.path.insert(0, "src")

import json
from pathlib import Path
from collections import defaultdict

output_file = open("../outputs_analysis.txt", "w", encoding="utf-8")

def log(msg):
    try:
        print(msg)
    except UnicodeEncodeError:
        # Skip console output on encoding error
        pass
    output_file.write(msg + "\n")
    output_file.flush()

# æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ
outputs = Path("../outputs")
all_tests = sorted(outputs.iterdir(), key=lambda d: d.stat().st_mtime)

log("=" * 100)
log("å…¨é¢åˆ†ææ‰€æœ‰ outputs ä¸­çš„é—®é¢˜")
log("=" * 100)
log(f"\nå…±æ‰¾åˆ° {len(all_tests)} ä¸ªæµ‹è¯•ç›®å½•\n")

# ç»Ÿè®¡ä¿¡æ¯
stats = {
    "total": 0,
    "with_result": 0,
    "segment_counts": [],
    "speaker_misalignment": 0,
    "long_segments": 0,
    "mixed_speaker_segments": 0,
}

detailed_issues = []

for test_dir in all_tests:
    if not test_dir.is_dir():
        continue

    result_file = test_dir / "result.json"
    if not result_file.exists():
        continue

    stats["total"] += 1
    stats["with_result"] += 1

    with open(result_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    seg_count = len(data["segments"])
    stats["segment_counts"].append((test_dir.name, seg_count))

    # åˆ†æé—®é¢˜
    issues = []

    # 1. æ£€æŸ¥æ®µè½æ•°å¼‚å¸¸
    if seg_count < 5:
        issues.append(f"âš ï¸ æ®µè½æ•°è¿‡å°‘ ({seg_count}ä¸ª) - å¯èƒ½è¯´è¯äººåˆå¹¶è¿‡åº¦")
    elif seg_count > 50:
        issues.append(f"âš ï¸ æ®µè½æ•°è¿‡å¤š ({seg_count}ä¸ª) - å¯èƒ½è¿‡åº¦åˆ†å‰²")

    # 2. æ£€æŸ¥é•¿æ®µè½ï¼ˆè¶…è¿‡ 30sï¼‰
    long_segs = []
    for seg in data["segments"]:
        duration = seg["end"] - seg["start"]
        if duration > 30:
            long_segs.append((seg["id"], duration, len(seg["text"])))

    if long_segs:
        stats["long_segments"] += len(long_segs)
        issues.append(f"âš ï¸ æœ‰ {len(long_segs)} ä¸ªè¶…é•¿ç‰‡æ®µ (>30s)")

    # 3. æ£€æŸ¥å¯èƒ½çš„è¯´è¯äººæ··åˆï¼ˆå¯å‘å¼æ£€æµ‹ï¼‰
    mixed_segs = []
    for seg in data["segments"]:
        text = seg["text"]
        # æ£€æµ‹é—®ç­”æ¨¡å¼ï¼š"...å—ï¼Ÿ" åé¢ç´§è·Ÿå›ç­”
        if "å—ï¼Ÿ" in text or "å—?" in text:
            # æ‰¾åˆ°é—®å·ä½ç½®
            for q in ["å—ï¼Ÿ", "å—?"]:
                if q in text:
                    idx = text.index(q)
                    # é—®å·åè¿˜æœ‰è¶…è¿‡ 20 ä¸ªå­—
                    if len(text) - idx - len(q) > 20:
                        mixed_segs.append({
                            "id": seg["id"],
                            "speaker": seg["speaker"],
                            "text_len": len(text),
                            "question": text[:idx+len(q)],
                            "answer": text[idx+len(q):idx+len(q)+30]
                        })
                        break

    if mixed_segs:
        stats["mixed_speaker_segments"] += len(mixed_segs)
        issues.append(f"ğŸ”´ æ£€æµ‹åˆ° {len(mixed_segs)} ä¸ªç–‘ä¼¼é—®ç­”æ··åˆç‰‡æ®µ")

    # 4. æ£€æŸ¥è¯´è¯äººåˆ†é…æ˜¯å¦åˆç†
    speaker_stats = defaultdict(lambda: {"count": 0, "duration": 0, "avg_duration": 0})
    for seg in data["segments"]:
        spk = seg["speaker"]
        duration = seg["end"] - seg["start"]
        speaker_stats[spk]["count"] += 1
        speaker_stats[spk]["duration"] += duration

    for spk, stats_dict in speaker_stats.items():
        stats_dict["avg_duration"] = stats_dict["duration"] / stats_dict["count"]

    # æ£€æµ‹å¼‚å¸¸ï¼šæŸä¸ªè¯´è¯äººåªæœ‰ 1-2 æ®µä½†æ—¶é•¿å¾ˆé•¿
    for spk, spk_stats in speaker_stats.items():
        if spk_stats["count"] <= 2 and spk_stats["duration"] > 30:
            issues.append(f"âš ï¸ {spk} åªæœ‰ {spk_stats['count']} æ®µä½†æ—¶é•¿ {spk_stats['duration']:.1f}s")

    # 5. æ£€æŸ¥è¯´è¯äººä¿¡æ¯
    for spk_id, spk_info in data["speakers"].items():
        display_name = spk_info["display_name"]
        gender = spk_info["gender"]
        kind = spk_info["kind"]

        # æ£€æŸ¥æ€§åˆ«è¯†åˆ«
        if display_name == "å¼ æ•™æˆ" and gender != "male":
            issues.append(f"ğŸ”´ å¼ æ•™æˆæ€§åˆ«è¯†åˆ«é”™è¯¯: {gender} (åº”ä¸º male)")
        if display_name == "ä¸»æŒäºº" and gender != "female":
            issues.append(f"âš ï¸ ä¸»æŒäººæ€§åˆ«è¯†åˆ«å¯èƒ½é”™è¯¯: {gender}")

    # è®°å½•è¯¦ç»†é—®é¢˜
    if issues:
        detailed_issues.append({
            "test": test_dir.name,
            "seg_count": seg_count,
            "issues": issues,
            "long_segs": long_segs,
            "mixed_segs": mixed_segs,
            "speaker_stats": dict(speaker_stats),
        })

# è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
log("\n" + "=" * 100)
log("æ±‡æ€»ç»Ÿè®¡")
log("=" * 100)
log(f"\næ€»æµ‹è¯•æ•°: {stats['total']}")
log(f"æœ‰ç»“æœçš„: {stats['with_result']}")
log(f"æ£€æµ‹åˆ°é—®é¢˜çš„: {len(detailed_issues)}")
log(f"è¯´è¯äººæ··åˆç‰‡æ®µæ€»æ•°: {stats['mixed_speaker_segments']}")
log(f"è¶…é•¿ç‰‡æ®µæ€»æ•°: {stats['long_segments']}")

# æ®µè½æ•°åˆ†å¸ƒ
log("\næ®µè½æ•°åˆ†å¸ƒ:")
seg_dist = defaultdict(int)
for name, count in stats["segment_counts"]:
    seg_dist[count] += 1

for count in sorted(seg_dist.keys()):
    log(f"  {count:3d} æ®µ: {seg_dist[count]} ä¸ªæµ‹è¯•")

# è¯¦ç»†é—®é¢˜æŠ¥å‘Š
log("\n" + "=" * 100)
log("è¯¦ç»†é—®é¢˜æŠ¥å‘Šï¼ˆæŒ‰ä¸¥é‡æ€§æ’åºï¼‰")
log("=" * 100)

# æŒ‰é—®é¢˜ä¸¥é‡æ€§æ’åº
def severity_score(issue_dict):
    score = 0
    for issue in issue_dict["issues"]:
        if "ğŸ”´" in issue:
            score += 10
        elif "âš ï¸" in issue:
            score += 1
    score += len(issue_dict["mixed_segs"]) * 5
    score += len(issue_dict["long_segs"]) * 2
    if issue_dict["seg_count"] < 5:
        score += 20  # æ®µè½æ•°è¿‡å°‘æ˜¯ä¸¥é‡é—®é¢˜
    return score

detailed_issues.sort(key=severity_score, reverse=True)

for idx, issue_dict in enumerate(detailed_issues, 1):
    log(f"\n[{idx}] {issue_dict['test']} ({issue_dict['seg_count']} æ®µ)")
    log("â”€" * 100)

    # åŸºæœ¬é—®é¢˜
    for issue in issue_dict["issues"]:
        log(f"  {issue}")

    # è¯´è¯äººç»Ÿè®¡
    log(f"\n  è¯´è¯äººç»Ÿè®¡:")
    for spk, spk_stats in issue_dict["speaker_stats"].items():
        log(f"    {spk}: {spk_stats['count']} æ®µ, {spk_stats['duration']:.1f}s æ€»æ—¶é•¿, "
            f"{spk_stats['avg_duration']:.1f}s å¹³å‡")

    # è¶…é•¿ç‰‡æ®µè¯¦æƒ…
    if issue_dict["long_segs"]:
        log(f"\n  è¶…é•¿ç‰‡æ®µè¯¦æƒ…:")
        for seg_id, duration, text_len in issue_dict["long_segs"]:
            log(f"    Segment {seg_id}: {duration:.1f}s, {text_len} å­—")

    # æ··åˆç‰‡æ®µè¯¦æƒ…
    if issue_dict["mixed_segs"]:
        log(f"\n  ç–‘ä¼¼é—®ç­”æ··åˆç‰‡æ®µ:")
        for mixed in issue_dict["mixed_segs"]:
            log(f"    Segment {mixed['id']} ({mixed['speaker']}, {mixed['text_len']}å­—):")
            log(f"      é—®: {mixed['question']}")
            log(f"      ç­”: {mixed['answer']}...")

# ç‰¹åˆ«å…³æ³¨ï¼šæ±‰è¯­æ°´å¹³è€ƒè¯•å¬åŠ›æµ‹è¯•
log("\n" + "=" * 100)
log("ç‰¹åˆ«åˆ†æï¼šæ±‰è¯­æ°´å¹³è€ƒè¯•å¬åŠ›æµ‹è¯•ï¼ˆåŒä¸€éŸ³é¢‘çš„å¤šæ¬¡æµ‹è¯•ï¼‰")
log("=" * 100)

hsk_tests = [item for item in stats["segment_counts"]
             if "æ±‰è¯­æ°´å¹³è€ƒè¯•å¬åŠ›" in item[0]]

if hsk_tests:
    log(f"\næ‰¾åˆ° {len(hsk_tests)} ä¸ªç›¸åŒéŸ³é¢‘çš„æµ‹è¯•ç»“æœ:")
    log("\næµ‹è¯•åç§° | æ®µè½æ•° | å·®å¼‚")
    log("â”€" * 100)

    counts = [count for _, count in hsk_tests]
    min_count = min(counts)
    max_count = max(counts)
    avg_count = sum(counts) / len(counts)

    for name, count in hsk_tests:
        diff = abs(count - avg_count)
        status = "âœ… æ­£å¸¸" if diff < 10 else "âš ï¸ åç¦»" if diff < 20 else "ğŸ”´ å¼‚å¸¸"
        log(f"{name} | {count:3d} | {status}")

    log(f"\nç»Ÿè®¡: æœ€å°‘ {min_count} æ®µ, æœ€å¤š {max_count} æ®µ, å¹³å‡ {avg_count:.1f} æ®µ")
    log(f"å˜å¼‚ç³»æ•°: {(max_count - min_count) / avg_count * 100:.1f}%")

    if max_count / min_count > 2:
        log("\nğŸ”´ ä¸¥é‡é—®é¢˜: æœ€å¤§/æœ€å°æ¯”å€¼ > 2ï¼Œè¯´æ˜ç»“æœæä¸ç¨³å®šï¼")

# è¯»å–ä¸€ä¸ªå…·ä½“çš„åä¾‹å­
log("\n" + "=" * 100)
log("å…·ä½“æ¡ˆä¾‹åˆ†æï¼šæœ€å·®ç»“æœ")
log("=" * 100)

if detailed_issues:
    worst = detailed_issues[0]
    test_dir = outputs / worst["test"]
    result_file = test_dir / "result.json"

    with open(result_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    log(f"\næµ‹è¯•: {worst['test']}")
    log(f"æ®µè½æ•°: {worst['seg_count']}")
    log(f"\nå®Œæ•´åˆ†æ®µåˆ—è¡¨:")
    log("â”€" * 100)

    for seg in data["segments"]:
        duration = seg["end"] - seg["start"]
        text_preview = seg["text"][:80] + ("..." if len(seg["text"]) > 80 else "")
        log(f"[{seg['id']:2d}] {seg['start']:6.1f}-{seg['end']:6.1f} ({duration:5.1f}s) {seg['speaker']}")
        log(f"     {text_preview}")

output_file.close()
log("\nåˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° ../outputs_analysis.txt")
